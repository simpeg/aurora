"""
This may wind up in aurora/transfer_function/kernel_dataset.py

"""

import copy
import pandas as pd

import mth5

from aurora.tf_kernel.helpers import channel_summary_to_run_summary
from aurora.tf_kernel.helpers import extract_run_summaries_from_mth5s


class KernelDataset():
    """
    Could be called "ProcessableDataset", KernelDataset, InputDataset or something
    like that.  This class is intended to work with mth5-derived channel_summary or
    run_summary dataframes, that specify time series intervals.

    This may actually be an extension of RunSummary

    The main idea is to specify one or two stations, together
    with a list of acquisition "runs" that can be merged into a "processing run".
    Each acquistion run can be further divided into non-overlapping chunks by specifying
    time-intervals associated with that acquistion run.  An empty iterable of
    time-intervals associated with a run is interpretted as the interval
    corresponding to the entire run.

    The time intervals can be used for several purposes but primarily:
    To specify contiguous chunks of data:
    1.  to STFT, that will be made into merged FC data structures
    2. to bind together into xarray time series, for eventual gap fill (and then STFT)
    3. To manage and analyse the availability of reference time series

    The basic data strucutre can be represented as a table or as a tree:
    Station --> run --> [Intervals],
    where the --> symbol is reads "branches that specify (a)".

    This is described in issue #118 https://github.com/simpeg/aurora/issues/118

    Desired Properties
    a) This should be able to take a dictionary (tree) and return the tabular (
    DataFrame) representation and vice versa.
    b) Ability (when there are two or more stations) apply interval intersection
    rules, so that only time intervals when both stations are acquiring data are
    returned

    From (a) above we can see that a simple table per station can
    represent the available data.  That table can be generated by default from
    the mth5, and intervals to exclude some data can be added as needed.

    (b) is really just the case of considering pairs of tables like (a)

    Thinking all that through, we actually want a baseclass StationDataset.
    The RR case could be handled by pairing two of these; StationPairDataset.  That
    would make this thing here a MultiStationDataset.


    2022-03-11:
    Following notes in Issue #118, want to get a fully populated dataframe from an mth5.
    If I pass a station_id, then get all runs, if I pass a (station_id, run_id),
    then just get the run start and end times.

    # Question: To return a copy or modify in-place when querying.  Need to decide on
    # standards and syntax.  Handling this in general is messy because every function
    # needs to be modified.  Maybe better to use a decorator that allows for df kwarg
    # to be passed, and if it is not passed the modification is done in place.
    # The user who doesn't want to modify in place can work with a clone.

    """
    def __init__(self, **kwargs):
        self.df = kwargs.get("df")
        self.local_station_id = kwargs.get("local_station_id")
        self.reference_station_id = kwargs.get("reference_station_id")

    def clone(self):
        return copy.deepcopy(self)

    def clone_dataframe(self):
        return copy.deepcopy(self.df)


    def from_run_summary(self, run_summary,
                         local_station_id,
                         reference_station_id=None):
        self.local_station_id = local_station_id
        self.reference_station_id = reference_station_id

        station_ids = [local_station_id,]
        if reference_station_id:
            station_ids.append(reference_station_id)
        df = restrict_to_station_list(run_summary.df, station_ids, inplace=False)
        df["remote"] = False
        if reference_station_id:
            cond = df.station_id == reference_station_id
            df.remote = cond
        self.df = df

    @property
    def add_duration(self):
        """
        """
        timedeltas = self.df.end - self.df.start
        durations = [x.seconds for x in timedeltas]
        self.df["duration"] = durations
        return

    def drop_runs_shorter_than(self, duration, units="s"):
        if units != "s":
            raise NotImplementedError
        if "duration" not in self.df.columns:
            self.add_duration
        drop_cond = self.df.duration < duration
        self.df.drop(self.df[drop_cond].index, inplace=True)
        self.df.reset_index()
        return



    def select_station_runs(self, station_runs_dict, keep_or_drop):
        df = select_station_runs(self.df, station_runs_dict, keep_or_drop)
        self.df = df
        return



    @property
    def is_single_station(self):
        if self.local_station_id:
            if self.reference_station_id:
                return False
            else:
                return True
        else:
            return False

    @property
    def is_remote_reference(self):
        raise NotImplementedError


    def restrict_run_intervals_to_simultaneous(self):
        raise NotImplementedError



def restrict_to_station_list(df, station_ids, inplace=True):
    """
    Drops all rows of run_summary dataframe where station_ids are NOT in
    the provided list of station_ids.  Operates on a deepcopy of self.df if a df
    isn't provided

    Parameters
    ----------
    station_ids: str or list of strings
        These are the station ids to keep, normally local and remote
    overwrite: bool
        If True, self.df is overwritten with the reduced dataframe

    Returns
    -------
        reduced dataframe with only stations associated with the station_ids
    """
    if isinstance(station_ids, str):
        station_ids = [station_ids, ]
    if not inplace:
        df = copy.deepcopy(df)
    cond1 = ~df["station_id"].isin(station_ids)
    df.drop(df[cond1].index, inplace=True)
    df = df.reset_index()
    return df


def select_station_runs(df, station_runs_dict, keep_or_drop, overwrite=True,):
    """
    Drops all rows where station_id==station_id, and run_id is NOT in the provided
     list of keep_run_ids.  Operates on a deepcopy df if inplace=False
    Uncommon use case the way this is coded, because it will restrict to a single
    station processing case.  Better to use drop runs, or a dict-style input

    Note1: Logic of keep/drop
    keep where cond1 is false
    keep where cond1 & cond2 both true
    drop where cond1 is true but cond2 is false

    Parameters
    ----------
    station_runs_dict: dict
        Keys are string ids of the stations to keep
        Values are lists of string labels for run_ids to keep
    keep_or_drop: str
        If "keep": returns df with only the station_rus specified in station_runs_dict
        If "drop": returns df with station_runs_dict excised
    overwrite: bool
        If True, self.df is overwritten with the reduced dataframe

    Returns
    -------
        reduced dataframe with only run_ids provided removed.
    """

    if not overwrite:
        df = copy.deepcopy(df)
    for station_id, run_ids in station_runs_dict.items():
        if isinstance(run_ids, str):
            run_ids = [run_ids, ]
        cond1 = df["station_id"]==station_id
        cond2 = df["run_id"].isin(run_ids)
        if keep_or_drop == "keep":
            drop_df = df[cond1 & ~cond2]
        else:
            drop_df = df[cond1 & cond2]

        df.drop(drop_df.index, inplace=True)
        df = df.reset_index()
    return df



def main():
    return


if __name__ == "__main__":
    main()
