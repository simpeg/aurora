{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214e6b75-89d2-4cd8-82b1-7a57832fa933",
   "metadata": {},
   "source": [
    "# Data Availability Wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef87ada-6c62-4dd2-b31f-34c5db63e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "from aurora.test_utils.earthscope.helpers import DATA_AVAILABILITY_CSV\n",
    "from aurora.test_utils.earthscope.helpers import PUBLIC_DATA_AVAILABILITY_PATH\n",
    "DATA_AVAILABILITY_PATH = PUBLIC_DATA_AVAILABILITY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d73454-db0a-4446-8ad4-5f09bc0bd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_files = DATA_AVAILABILITY_PATH.glob(\"mt_availability_*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3fec13-dc57-4472-a398-0f6a79e01c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_files = list(availability_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1922d98-b281-40f9-8741-97cb20e8b3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_XC.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_8P.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_US.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_EM.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_4P.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_1H.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_SF.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_IU.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_ZU.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_N4.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_Z7.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_8J.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_AV.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_7I.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_SN.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_BK.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_NV.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_YB.txt'),\n",
       " PosixPath('/home/kkappler/.cache/earthscope/data_availability/public/mt_availability_II.txt')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "availability_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b139faf8-9339-41c7-8f7a-d1de691fde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for af in availability_files:\n",
    "    df = pd.read_csv(af, parse_dates=[\"Earliest\",\"Latest\",\"Span\"])\n",
    "    #print(df)\n",
    "    df_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(df_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15fa9bc-d708-4dd6-9bf2-f09acf4abe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164966\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff2b804-4fa9-4e5b-a5e1-9172829f2485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#Network', 'Station', 'Location', 'Channel', 'Quality', 'SampleRate',\n",
       "       'Earliest', 'Latest', 'Span'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1ca4d99-71cd-4d4c-99e9-1129c00a6c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Network: 19 unique values: \n",
      " ['XC' '8P' 'US' 'EM' '4P' '1H' 'SF' 'IU' 'ZU' 'N4' 'Z7' '8J' 'AV' '7I'\n",
      " 'SN' 'BK' 'NV' 'YB' 'II']\n",
      "Station: 2329 unique values: \n",
      " ['FL001' 'FL002' 'FL003' ... 'MOJA' 'BFO' 'PFO']\n",
      "Location: 14 unique values: \n",
      " ['--' 40 9 '00' '40' 2 '01' '04' 'B1' 'W1' 'W2' 'W3' 0 20]\n",
      "Channel: 34 unique values: \n",
      " ['MFE' 'MFN' 'MFZ' 'MQE' 'MQN' 'LFE' 'LFN' 'LFZ' 'LQE' 'LQN' 'LF1' 'LF2'\n",
      " 'VFE' 'VFN' 'VFZ' 'VQE' 'VQN' 'CF1' 'GF1' 'GF2' 'UFZ' 'VF1' 'VF2' 'CFZ'\n",
      " 'UF1' 'UF2' 'BQ2' 'MF1' 'MF2' 'BF1' 'BF2' 'BFE' 'BFN' 'BFZ']\n",
      "Quality: 1 unique values: \n",
      " ['M']\n",
      "SampleRate: 13 unique values: \n",
      " [8.0000e+00 1.0000e+00 2.0000e-01 3.3333e-02 4.0000e+00 2.5000e+02\n",
      " 4.0000e+03 1.0000e-02 1.0000e-01 5.0000e+02 2.0000e+02 4.0000e+01\n",
      " 5.0000e+00]\n",
      "Earliest: 59139 unique values: \n",
      " <DatetimeArray>\n",
      "[       '2015-01-08 19:49:15+00:00',        '2015-01-19 16:16:31+00:00',\n",
      "        '2015-01-09 17:24:25+00:00',        '2015-01-19 19:33:06+00:00',\n",
      "        '2015-01-10 15:52:11+00:00',        '2015-01-11 22:19:01+00:00',\n",
      "        '2015-01-18 19:39:53+00:00',        '2015-01-10 20:09:23+00:00',\n",
      "        '2015-01-18 16:16:41+00:00',        '2015-01-30 18:49:52+00:00',\n",
      " ...\n",
      " '2009-10-22 18:49:46.069500+00:00', '2009-10-22 20:45:39.069500+00:00',\n",
      " '2009-10-26 18:05:39.069500+00:00', '2009-11-04 18:40:44.069500+00:00',\n",
      " '2009-11-04 18:54:00.069500+00:00', '2009-11-11 17:54:00.069500+00:00',\n",
      " '2009-12-21 20:04:22.069500+00:00', '2009-12-21 20:17:07.069500+00:00',\n",
      " '2009-12-23 17:09:07.069500+00:00', '2010-01-07 17:41:07.069500+00:00']\n",
      "Length: 59139, dtype: datetime64[ns, UTC]\n",
      "Latest: 60979 unique values: \n",
      " <DatetimeArray>\n",
      "['2015-01-19 14:54:54.875000+00:00', '2015-01-29 16:18:14.875000+00:00',\n",
      " '2015-01-19 18:57:12.875000+00:00', '2015-01-29 13:19:09.875000+00:00',\n",
      " '2015-01-11 21:54:01.875000+00:00', '2015-01-18 19:00:24.875000+00:00',\n",
      " '2015-01-30 13:28:33.500000+00:00', '2015-01-30 13:28:33.875000+00:00',\n",
      " '2015-01-18 13:36:27.875000+00:00', '2015-01-31 17:23:43.875000+00:00',\n",
      " ...\n",
      " '2009-11-04 18:48:43.069500+00:00', '2009-11-11 17:49:59.069500+00:00',\n",
      " '2009-12-21 20:01:59.069500+00:00', '2009-12-21 20:12:21.069500+00:00',\n",
      " '2009-12-23 17:05:06.069500+00:00', '2010-01-07 17:37:06.069500+00:00',\n",
      " '2010-04-19 19:05:06.069500+00:00', '2018-10-20 11:01:33.069536+00:00',\n",
      " '2019-11-20 23:06:31.069538+00:00', '2020-08-12 15:44:11.069539+00:00']\n",
      "Length: 60979, dtype: datetime64[ns, UTC]\n",
      "Span: 14647 unique values: \n",
      " ['10 days 19:05:39.875000' '10 days 00:01:43.875000'\n",
      " '10 days 01:32:47.875000' ... '2 days 19:47:59.999997'\n",
      " '0 days 19:00:07.999999' '21 days 23:07:59.000001']\n"
     ]
    }
   ],
   "source": [
    "for col in merged_df.columns:\n",
    "    unique_values = merged_df[col].unique()\n",
    "    print(f\"{col}: {len(unique_values)} unique values: \\n {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e26f1-81e5-489e-b3b0-bdf52436ba33",
   "metadata": {},
   "source": [
    "Looks like 34 different channel codes encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4fd726a-38fc-45e6-8f9d-b1f9a81d6257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MFE', 'MFN', 'MFZ', 'MQE', 'MQN', 'LFE', 'LFN', 'LFZ', 'LQE',\n",
       "       'LQN', 'LF1', 'LF2', 'VFE', 'VFN', 'VFZ', 'VQE', 'VQN', 'CF1',\n",
       "       'GF1', 'GF2', 'UFZ', 'VF1', 'VF2', 'CFZ', 'UF1', 'UF2', 'BQ2',\n",
       "       'MF1', 'MF2', 'BF1', 'BF2', 'BFE', 'BFN', 'BFZ'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_channel_codes = merged_df.Channel.unique()\n",
    "unique_channel_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "972f9ce8-8515-4830-8ff5-3c38b4ea30b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'U', 'L', 'G', 'V', 'M', 'C']\n"
     ]
    }
   ],
   "source": [
    "sample_rate_codes = [x[0] for x in unique_channel_codes]\n",
    "sample_rate_codes = list(set(sample_rate_codes))\n",
    "print(sample_rate_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb427f41-b04f-43ff-a8ae-1c93c3b8711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B ['BQ2', 'BF1', 'BF2', 'BFE', 'BFN', 'BFZ']\n",
      "U ['UFZ', 'UF1', 'UF2']\n",
      "L ['LFE', 'LFN', 'LFZ', 'LQE', 'LQN', 'LF1', 'LF2']\n",
      "G ['GF1', 'GF2']\n",
      "V ['VFE', 'VFN', 'VFZ', 'VQE', 'VQN', 'VF1', 'VF2']\n",
      "M ['MFE', 'MFN', 'MFZ', 'MQE', 'MQN', 'MF1', 'MF2']\n",
      "C ['CF1', 'CFZ']\n"
     ]
    }
   ],
   "source": [
    "for src in sample_rate_codes:\n",
    "    print(src, [x for x in unique_channel_codes if x[0]==src])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f077a-03ef-4c5e-a944-7d7a46fe34c2",
   "metadata": {},
   "source": [
    "Options for doing MT are {V, M, B, L}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542e036-f7a7-4ee5-9fdb-9654289fddd0",
   "metadata": {},
   "source": [
    "OK, so FDSN does not support the concept of run, so we cannot groupby run (yet) ... \n",
    "\n",
    "Ideally, we would iterate over this df, calling each channel, and it would land in an appropriate spot in an h5 ...  that would be nice \n",
    "@Jared .. to discuss this concept.\n",
    "\n",
    "But if it doesn't work, we can start by grouping the rows of the df into blocks by Net-Sta-Loc (all channels together getting called)\n",
    "\n",
    "\n",
    "So lets, try grouping these into Runs and see in anything untoward happens ... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45f8395-058b-4e74-925c-7e3f727e883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--    82583\n",
       "9     44463\n",
       "40    27019\n",
       "20     4950\n",
       "40     2356\n",
       "0      1969\n",
       "00      761\n",
       "W1      273\n",
       "W2      271\n",
       "W3      266\n",
       "B1       21\n",
       "2        14\n",
       "01       10\n",
       "04       10\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = merged_df[\"Location\"].unique()\n",
    "merged_df.Location.value_counts()\n",
    "# for loc_code in locations:\n",
    "#     print(len(loc_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f93e471-90b9-4d60-a804-689195437a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_sta_grouper = merged_df.groupby([\"#Network\", \"Station\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61736ac4-bde6-48ed-ae65-a831b41158f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3401"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net_sta_grouper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5192d0-91b0-4205-acb0-70ff852be58f",
   "metadata": {},
   "source": [
    "Interesting, there are 3401 Net-Stas, but only 2329 Station codes ... which suggests that station names are used more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24ba74bb-bdbd-475c-8b48-3c953814f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3407\n"
     ]
    }
   ],
   "source": [
    "net_sta_loc_grouper = merged_df.groupby([\"#Network\", \"Station\", \"Location\"])\n",
    "print(len(net_sta_loc_grouper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c82b7a-7c80-4f5f-8f21-5cd470370615",
   "metadata": {},
   "source": [
    "And look, even more when we add Loc, suggesting that a Net-Sta was moved to another spot ... gadzooks - what have we gotten ourselves into ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db9ba76e-966b-4d50-a7c5-0c62335370d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for net_sta_loc, nsl_df in net_sta_grouper:\n",
    "#     print(net_sta_loc, len(nsl_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca8665-6831-45dd-9817-c9634c689309",
   "metadata": {},
   "source": [
    "### Look for \"Normal\" MT Stations, these have 5-channels\n",
    "\n",
    "These net-sta-loc combinations will be appropriate for aurora MT processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34881ecf-94a2-44b8-8e8b-1e64e9cfba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 251 net_sta_loc combos with 5 channels\n",
      "These are found in the following networks: \n",
      " ['EM', 'ZU', 'XC', '1H', '8P', '4P', 'Z7']\n"
     ]
    }
   ],
   "source": [
    "five_channel_net_sta_locs = []\n",
    "i_not_weird = 0\n",
    "not_weird_networks = [] \n",
    "for net_sta_loc, nsl_df in net_sta_loc_grouper:\n",
    "    network = net_sta_loc[0]\n",
    "    n_ch = len(nsl_df)\n",
    "    if n_ch == 5:  # this is \"normal\"\n",
    "        i_not_weird+=1\n",
    "        if network not in not_weird_networks:\n",
    "            not_weird_networks.append(network)\n",
    "            not_weird_networks = list(set(not_weird_networks))\n",
    "        five_channel_net_sta_locs.append(net_sta_loc)\n",
    "print(f\"There are {i_not_weird} net_sta_loc combos with 5 channels\")\n",
    "print(f\"These are found in the following networks: \\n {not_weird_networks}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb22dd1-0c8f-4698-9b5a-f9941ab7b6c5",
   "metadata": {},
   "source": [
    "### Check if location code is ever non degenerate for the cases of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e14160aa-eb4f-459b-ab25-4dc3f27cb765",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 unique location codes: \n",
      " ['--']\n"
     ]
    }
   ],
   "source": [
    "locs = [x[2] for x in five_channel_net_sta_locs]\n",
    "unique_locs = list(set(locs))\n",
    "print(f\"Found {len(unique_locs)} unique location codes: \\n {unique_locs}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879cfc2-eaa2-46a4-b0e0-f1148711a6c1",
   "metadata": {},
   "source": [
    "OK, location is moot, and we can use as an iterator:\n",
    "\n",
    "five_channel_net_sta_locs\n",
    "\n",
    "So before launching, let's create a dataframe of the list of net-stas so that there \n",
    "is a shareable csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "947bee7a-ef94-43b3-ae3c-3fb60b134c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    network station\n",
      "0        1H   MB013\n",
      "1        1H   MC011\n",
      "2        1H   MC014\n",
      "3        1H   MC016\n",
      "4        1H   MD010\n",
      "..      ...     ...\n",
      "246      XC   FL020\n",
      "247      XC   FL022\n",
      "248      Z7   KAN04\n",
      "249      Z7   KAN05\n",
      "250      ZU   KSQ29\n",
      "\n",
      "[251 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "n_sources = len(five_channel_net_sta_locs)\n",
    "networks = n_sources * [\"\"]\n",
    "stations = n_sources * [\"\"]\n",
    "i_source=0\n",
    "for net_sta_loc in five_channel_net_sta_locs:\n",
    "    network = net_sta_loc[0]\n",
    "    station = net_sta_loc[1]\n",
    "    #print(station)\n",
    "    networks[i_source] = network\n",
    "    stations[i_source] = station\n",
    "    i_source+= 1\n",
    "    \n",
    "df = pd.DataFrame(data={\"network\":networks, \"station\":stations})\n",
    "print(df)\n",
    "df.to_csv(DATA_AVAILABILITY_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00f6247e-61ed-431d-b74f-9042413e7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164966\n",
      "1365\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))\n",
    "reduced_df = merged_df[merged_df.Station.isin(stations)]\n",
    "reduced_df = reduced_df[reduced_df[\"#Network\"].isin(networks)]\n",
    "print(len(reduced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b00d9716-42a5-419e-842a-348e3286e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MFE', 'MFN', 'MFZ', 'MQE', 'MQN', 'LFE', 'LFN', 'LFZ', 'LQE',\n",
       "       'LQN', 'VFE', 'VFN', 'VFZ', 'VQE', 'VQN'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.Channel.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora",
   "language": "python",
   "name": "aurora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
