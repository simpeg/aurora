
name: Testing

on:
  push:
    branches:
      - '*'
  pull_request:
    branches:
      - '*'

jobs:
  setup-build:
    name: Ex1 (${{ matrix.python-version }}, ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.10"]

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Cache MTH5 test files
        uses: actions/cache@v4
        with:
          path: ~/.cache/aurora
          key: mth5-test-files-${{ runner.os }}-${{ hashFiles('tests/conftest.py') }}
          restore-keys: |
            mth5-test-files-${{ runner.os }}-

      - name: Create virtual environment and install dependencies
        run: |
          uv venv --python ${{ matrix.python-version }}
          source .venv/bin/activate
          uv pip install --upgrade pip
          uv pip install -e ".[dev,test]"
          uv pip install mt_metadata[obspy]
          uv pip install mth5
          uv pip install git+https://github.com/kujaku11/mth5_test_data.git
          # Explicitly include nbconvert & ipykernel
          uv pip install jupyter nbconvert ipykernel pytest pytest-cov pytest-timeout codecov
          python -m ipykernel install --user --name "python3"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc

      - name: Execute Jupyter Notebooks catching failures
        shell: bash
        run: |
          source .venv/bin/activate
          set -o pipefail
          # NOTE: Do not set -e; we want to continue through failures.

          failures=()
          notebooks=(
            "docs/examples/dataset_definition.ipynb"
            "docs/examples/operate_aurora.ipynb"
            "docs/tutorials/pkd_units_check.ipynb"
            "docs/tutorials/pole_zero_fitting/lemi_pole_zero_fitting_example.ipynb"
            "docs/tutorials/processing_configuration.ipynb"
            "docs/tutorials/process_cas04_multiple_station.ipynb"
            "docs/tutorials/synthetic_data_processing.ipynb"
          )

          mkdir -p executed

          for nb in "${notebooks[@]}"; do
            out="executed/$(basename "${nb%.ipynb}").executed.ipynb"
            echo "Executing: ${nb}"
            # Use uv-managed Python and call nbconvert as a module (no PATH reliance)
            uv run python -m jupyter nbconvert \
              --to notebook \
              --execute \
              --ExecutePreprocessor.allow_errors=True \
              --ExecutePreprocessor.timeout=600 \
              --output "${out}" \
              "${nb}"
            rc=$?
            if [[ $rc -ne 0 ]]; then
              echo "⚠️ nbconvert process failed for ${nb} (rc=${rc})."
              failures+=("${nb}")
            fi
          done

          # Detect embedded cell errors even if nbconvert returned 0
          errs=()
          if ls executed/*.executed.ipynb >/dev/null 2>&1; then
            if uv run python - <<'PY'
              import json, glob
              for fn in glob.glob("executed/*.executed.ipynb"):
                  with open(fn, "r", encoding="utf-8") as f:
                      nb = json.load(f)
                  for cell in nb.get("cells", []):
                      for o in cell.get("outputs", []):
                          if o.get("output_type") == "error":
                              print(fn)
                              raise SystemExit(1)
              raise SystemExit(0)
              PY
            then
              :
            else
              # Only add notebooks that actually have errors
              for fn in executed/*.executed.ipynb; do
                if uv run python - <<'PY2'
              import json, sys
              fn = sys.argv[1]
              with open(fn, "r", encoding="utf-8") as f:
                  nb = json.load(f)
              for cell in nb.get("cells", []):
                  for o in cell.get("outputs", []):
                      if o.get("output_type") == "error":
                          raise SystemExit(1)
              raise SystemExit(0)
              PY2
                "$fn"
                then
                  : # no error in this notebook
                else
                  errs+=("$fn")
                fi
              done
            fi
          fi

          if (( ${#failures[@]} > 0 || ${#errs[@]} > 0 )); then
            echo ""
            echo "======= Summary ======="
            [[ ${#failures[@]} -gt 0 ]] && echo "nbconvert crashed/timeout for:" "${failures[@]}"
            [[ ${#errs[@]} -gt 0 ]] && echo "Cell errors embedded in:" "${errs[@]}"
            exit 1
          fi

      - name: Upload executed notebooks as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: executed-notebooks
          path: executed/

      - name: "Upload coverage reports to Codecov"
        uses: codecov/codecov-action@v4
        with:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: false
          flags: tests

      # Note: these conditions won't match python-version 3.10; adjust if desired.
      - name: Build Doc
        if: ${{ (github.ref == 'refs/heads/main') && (matrix.python-version == '3.8') }}
        run: |
          source .venv/bin/activate
          cd docs
          make html
          cd ..

      - name: GitHub Pages
        if: ${{ (github.ref == 'refs/heads/main') && (matrix.python-version == '3.8') }}
        uses: crazy-max/ghaction-github-pages@v2.5.0
        with:
          build_dir: docs/_build/html
          jekyll: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
